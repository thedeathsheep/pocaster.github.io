---
layout: post
title: AI学习笔记2
cover-img: /assets/img/0028963732_0.jpg
thumbnail-img: /assets/img/0028963732_0.jpg
share-img: /assets/img/0028963732_0.jpg
tags: [Public, AI]
author: pocaster
---

# AI学习笔记2

## 第一部分：大语言模型（Large Language Models, LLMs）

### 1. 基础概念
**核心定义**：基于海量文本数据训练的**超大规模神经网络**，能够理解、生成和推理自然语言。

### 2. 核心技术
#### 2.1 基础架构
- **Transformer**（2017年提出）
  - 核心组件：**自注意力机制（Self-Attention）**
  - 关键优势：解决了RNN的长程依赖问题
- **预训练+微调范式**
  - 预训练：大规模无标注文本学习
  - 微调：针对具体任务调整

#### 2.2 训练方法

| 方法 | 代表模型 | 特点 |
|------|----------|------|
| 自回归 | GPT系列 | 从左到右逐词生成 |
| 自编码 | BERT | 双向上下文编码 |
| 混合模式 | T5、BART | 结合生成与理解 |

### 3. 代表性模型

| 模型 | 发布机构 | 参数量 | 特点 |
|------|----------|--------|------|
| GPT-3 | OpenAI | 1750亿 | 通用生成能力 |
| PaLM | Google | 5400亿 | 多模态融合 |
| LLaMA | Meta | 70亿~650亿 | 开源轻量化 |
| ChatGPT | OpenAI | GPT-3.5/4 | 对话优化 |
| Claude | Anthropic | 未公开 | 安全性高 |

### 4. 能力与局限
#### 4.1 核心能力
1. 文本生成
2. 语言理解
3. 逻辑推理
4. 多语言支持
5. 多模态扩展

#### 4.2 局限性
1. 幻觉问题
2. 偏见与安全风险
3. 高算力需求

### 5. 技术挑战
- 训练优化
- 对齐与安全
- 轻量化部署

### 6. 未来方向
1. 多模态融合
2. 具身智能
3. 可解释性
4. 降低门槛

---

## 第二部分：人工神经网络（ANN）

### 1. 基础概念
**核心定义**：模仿生物神经元结构和功能构建的**计算模型**，通过多层非线性变换学习数据中的复杂模式。

### 2. 生物与人工对比

| 生物神经元 | 人工神经元 |
|------------|------------|
| 细胞体、树突、轴突 | 输入、权重、激活函数 |
| 电化学信号传递 | 数值计算 |
| 突触可塑性 | 权重调整 |

### 3. 核心组件
#### 3.1 基本结构
- 输入层
- 隐藏层
- 输出层

#### 3.2 数学操作
1. 加权求和
2. 激活函数
3. 损失函数

### 4. 训练过程
#### 4.1 前向传播
#### 4.2 反向传播
#### 4.3 优化算法

### 5. 网络类型

| 类型 | 结构特点 | 典型应用 |
|------|----------|----------|
| FNN | 单向传播 | 图像分类 |
| CNN | 局部连接 | 计算机视觉 |
| RNN | 时间循环 | 语音识别 |
| Transformer | 自注意力 | 大语言模型 |
| GNN | 图结构 | 社交网络 |

### 6. 优缺点
#### 6.1 优势
1. 非线性建模
2. 特征自动学习
3. 端到端训练

#### 6.2 局限性
1. 黑箱问题
2. 数据依赖
3. 计算成本高

### 7. 应用场景
- 图像处理
- 自然语言处理
- 游戏AI
- 自动驾驶

---

## 第三部分：文本处理与数值化

### 1. 处理流程
```
原始文本 → 分词/清洗 → 向量化 → 建模 → 应用
```

### 2. 数值化方法
#### 2.1 词袋模型
#### 2.2 TF-IDF
#### 2.3 词嵌入

### 3. 算法理解机制
- 距离计算
- 统计共现
- 概率建模
- 分类聚类

### 4. 语义表示原理
1. 分布式假设
2. 低维稠密向量
3. 监督信号

### 5. 实例演示
```python
# 示例代码
from sklearn.metrics.pairwise import cosine_similarity
vec1 = [0.2, 0.8]  # "猫"
vec2 = [0.3, 0.7]  # "狗"
print(cosine_similarity([vec1], [vec2]))
```

### 6. 核心公式
$$\text{语义关系} \approx \text{向量空间中的几何关系}$$


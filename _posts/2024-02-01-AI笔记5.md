---
layout: post
title: AI学习笔记5
cover-img: /assets/img/0028963732_0.jpg
thumbnail-img: /assets/img/0028963732_0.jpg
share-img: /assets/img/0028963732_0.jpg
tags: [Public, AI]
author: pocaster
published: false
math: true
mermaid: true
---

LLM（大语言模型）训练流程:

<div class="mermaid">
graph TD
    A[数据收集] --> B[数据清洗]
    B --> C[数据预处理]
    C --> D[模型架构设计]
    D --> E[预训练]
    E --> F[微调]
    F --> G[评估]
    G --> H{性能达标?}
    H -->|是| I[部署]
    H -->|否| D
</div>

### 训练流程详解：

1. **数据收集阶段**
   - 爬取高质量文本数据（网页/书籍/论文等）
   - 获取对话数据集（客服记录/论坛讨论等）
   - 典型数据量：TB级到PB级

2. **数据清洗**
   - 去除HTML标签/广告/重复内容
   - 过滤低质量/有害内容
   - 语言识别和分类

3. **数据预处理**
   - 分词（WordPiece/BPE等算法）
   - 构建词汇表（通常50K-100K tokens）
   - 数据格式转换（TFRecords/JSONL等）

4. **模型架构设计**
   - Transformer结构选择（GPT/BERT等）
   - 确定参数量（层数/注意力头数/隐层维度）
   - 示例配置：
     ```python
     {
       "n_layer": 32,
       "n_head": 32,
       "d_model": 4096,
       "vocab_size": 50257
     }
     ```

5. **预训练阶段**
   - 目标函数：语言建模（预测下一个token）
   - 硬件配置：多节点GPU集群（如A100 80GB x 512）
   - 典型训练时间：数千GPU小时
   - 关键技术：
     - 混合精度训练
     - 梯度检查点
     - 数据并行+模型并行

6. **微调阶段**
   - 指令微调（Instruction Tuning）
   - 人类反馈强化学习（RLHF）
   - 领域适应（医疗/法律等专业领域）

7. **评估环节**
   - 基准测试：
     - MMLU（多学科理解）
     - GSM8K（数学推理）
     - HumanEval（代码生成）
   - 人工评估（流畅性/事实性/安全性）

8. **部署准备**
   - 模型量化（FP16/INT8）
   - 推理优化（KV缓存/动态批处理）
   - API服务封装


好的！我用最通俗的方式解释每个技术点，配合生活化的比喻：

---

### 1. **数据收集 → 像买菜**
- **做什么**：从网上（维基百科、电子书、论坛等）抓取各种文本
- **比喻**：就像去菜市场买各种食材（青菜/肉/调料），要挑新鲜的（高质量数据）

---

### 2. **数据清洗 → 像洗菜切菜**
- **做什么**：
  - 去广告/乱码 → 好比摘掉烂菜叶
  - 删重复内容 → 好比去掉买多的土豆
  - 过滤不良信息 → 像剔除发霉的食材
- **关键工具**：正则表达式（像智能筛子）

---

### 3. **数据预处理 → 像备菜**
- **分词**：把句子切成小段
  （例："我爱AI" → ["我", "爱", "AI"]）
- **构建词汇表**：
  像准备调料盒，把"番茄/西红柿"统一成"番茄"
- **典型问题**：
  遇到"GPT-4"这种新词怎么办？ → 用BPE算法（像乐高拼新词）

---

### 4. **模型架构设计 → 搭积木**
- **Transformer**：
  核心结构像多层三明治，每层都有：
  - **自注意力机制**：读句子时会自动划重点
    （比如看到"苹果"时，能区分是水果还是手机）
  - **前馈网络**：像消化系统，处理吸收的信息

---

### 5. **预训练 → 高考前刷题**
- **学习方式**：
  让AI做"完形填空"（预测下一个词）
  例：输入"中国的首都是___"，要输出"北京"
- **硬件需求**：
  相当于让500个学霸（GPU）一起刷5年高考3年模拟
- **省显存技巧**：
  - 混合精度：用计算器时只记小数点后2位
  - 梯度检查点：只存重点错题

---

### 6. **微调 → 专业特训**
- **指令微调**：
  教AI按指令做事，比如：
  ```
  输入："写首诗"
  输出："春眠不觉晓..."
  ```
- **RLHF**：
  像教小朋友，做得好给糖（奖励模型），做错就纠正

---

### 7. **评估 → 期末考试**
- **自动测试**：
  - MMLU：像综合试卷（数学/历史/科学都考）
  - GSM8K：专门考数学应用题
- **人工测试**：
  让真人判断AI回答是否像正常人

---

### 8. **部署 → 开店营业**
- **模型量化**：
  把百科全书压缩成口袋书（模型变小）
- **推理优化**：
  像快餐店备餐，提前准备好常用材料（KV缓存）
- **API封装**：
  给模型装个收银台（输入问题→输出回答）

---

### 举个完整例子🌰：
**用户问**："推荐北京的美食"
**AI如何工作**：
1. 分词 → ["推荐", "北京", "的", "美食"]
2. 自注意力 → 聚焦"北京"和"美食"
3. 从训练记忆里找关联（北京→烤鸭/卤煮）
4. 按指令格式输出："北京推荐尝试：1. 烤鸭 2..."

## **编排架构**

编排架构（Orchestration Architecture）是一种用于管理和协调多个独立服务或组件以完成复杂任务的系统设计模式。它通常用于微服务、分布式系统或自动化流程中，通过一个中央控制器（编排器）来定义和执行任务流程。

### 核心概念：
1. **编排器（Orchestrator）**
   作为核心组件，负责：
   - 定义任务顺序和依赖关系
   - 调用各个服务
   - 处理错误和重试机制
   - 维护整体状态

2. **参与者（Participants）**
   是被调用的独立服务或组件，通常：
   - 无状态且职责单一
   - 不知道整体流程
   - 通过API/事件响应编排器

### 典型特点：
- **集中控制**：所有逻辑集中在编排器中
- **同步通信**：通常采用请求-响应模式
- **流程可视化**：整个业务流程明确体现在编排器中
- **事务管理**：支持SAGA等分布式事务模式

### 常见实现场景：
1. **微服务协调**：如电商下单流程（库存→支付→物流）
2. **数据流水线**：ETL数据处理流程
3. **自动化部署**：CI/CD管道管理
4. **业务工作流**：如保险理赔审批流程

### 对比编排（Orchestration）与协同（Choreography）：
| 特性         | 编排架构                  | 协同架构                  |
|--------------|--------------------------|--------------------------|
| 控制方式     | 集中式                   | 分布式                   |
| 耦合度       | 编排器与参与者耦合       | 服务间通过事件松散耦合   |
| 复杂度       | 编排器可能成为单点故障   | 更难追踪整体流程         |
| 适用场景     | 强事务要求的流程         | 高扩展性的异步系统       |

### 常见工具：
- 工作流引擎：Camunda, Airflow
- 云服务：AWS Step Functions, Azure Logic Apps
- 编排框架：Cadence, Temporal


在AI应用开发中，**编排架构**（Orchestration Architecture）特指对AI模型、数据处理和服务组件进行**流程化调度与协同管理**的设计模式。其核心目标是解决AI系统固有的复杂性，例如多模型协作、资源动态分配和异构计算整合。以下是深度解析：

---

### **AI编排架构的三大核心作用**
1. **流水线自动化**
   - 串联数据预处理→模型推理→后处理→反馈闭环
   - 例：CV任务中的 `图像清洗 → ResNet分类 → 结果可视化` 流水线

2. **资源动态调度**
   - 根据负载自动扩缩容GPU实例（如K8s + Kubeflow）
   - 优先级调度：实时推理任务抢占批处理训练资源

3. **异构组件整合**
   - 协调Python模型服务与Java业务系统（通过gRPC/REST）
   - 混合云场景：本地化敏感数据处理 + 公有云大模型调用

---

### **典型AI编排架构分层**
<div class="mermaid">
graph TD
    A[用户请求] --> B(API网关)
    B --> C{编排引擎}
    C --> D[数据预处理服务]
    C --> E[模型A: TensorFlow Serving]
    C --> F[模型B: PyTorch ONNX]
    C --> G[业务规则引擎]
    G --> H[(结果存储)]
</div>

---

### **关键技术组件**  
1. **工作流引擎**
   - **Airflow**：定时调度模型重训练任务
     ```python
     # DAG示例：每天凌晨训练模型
     with DAG('model_retrain', schedule_interval='@daily'):
         preprocess = PythonOperator(task_id='preprocess_data', python_callable=clean_data)
         train = KubernetesPodOperator(task_id='train_model', image='tf-training:latest')
         deploy = BashOperator(task_id='deploy', bash_command='kubectl apply -f model.yaml')
         preprocess >> train >> deploy
     ```
   - **Metaflow**：数据科学家友好的ML流水线工具

2. **模型服务网格**
   - 使用**Seldon Core**或**KServe**实现：
     - 灰度发布（A/B测试模型版本）
     - 自动缩放（HPA基于QPS调整副本数）

3. **分布式协调**
   - **Ray**：动态编排强化学习中的Actor任务
     ```python
     @ray.remote(num_gpus=1)
     class ModelInference:
         def __call__(self, input):
             return model.predict(input)
   
     # 并行调用多个模型
     results = ray.get([ModelInference.remote(x) for x in inputs])
     ```

---

### **AI编排的特殊挑战**
1. **长时任务管理**
   - 模型训练可能持续数小时，需持久化编排状态
   - 方案：Celery + Redis保存任务上下文

2. **数据依赖传递**
   - 避免重复预处理（如通过**Dask**缓存中间结果）
   - 版本控制：MLMD（ML Metadata）记录数据→模型对应关系

3. **弹性容错**
   - GPU节点故障时自动迁移任务（如PyTorch Elastic）

---

### **与普通编排的差异点**
| 维度         | AI编排                      | 传统业务编排             |
|--------------|----------------------------|--------------------------|
| 资源需求     | GPU/NPU敏感调度            | 通用CPU计算              |
| 流程可变性   | 动态调整模型组合（如LLM路由）| 固定业务流程            |
| 监控指标     | 关注吞吐量/显存利用率       | 侧重TPS/响应时间         |
| 典型工具链   | Kubeflow, MLflow           | Camunda, Apache Airflow  |

---

### **实际应用案例**
1. **推荐系统**
   ```python
   # 多阶段推荐编排
   def recommend(user_id):
       with Flow('rec_flow') as f:
           user_features = get_user_features(user_id)
           recall = parallel(
               faiss_knn(user_features),
               hot_list()
           )
           rank = xgboost_ranking(recall)
           filter = business_rules(rank)
       return filter.run()
   ```

2. **大模型应用**
   - 使用**LangChain**编排：
     ```
     用户问题 → 向量检索 → GPT-4生成 → 合规性检查 → 输出
     ```

---

### **架构选型建议**
1. **轻量级场景**：Prefect + FastAPI
2. **K8s生态**：Argo Workflows + KServe
3. **端到端ML**：Metaflow（适合数据科学团队）
4. **实时推理**：NVIDIA Triton + Redis流处理

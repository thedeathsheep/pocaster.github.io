---
layout: post
title: AI学习笔记8
cover-img: /assets/img/0028963732_0.jpg
thumbnail-img: /assets/img/0028963732_0.jpg
share-img: /assets/img/0028963732_0.jpg
tags: [Public, AI]
author: pocaster
published: false
math: true
mermaid: true
---

RAG（检索增强生成）的核心组件构成了其动态结合 **外部知识检索** 和 **生成模型** 的能力。以下是详细拆解：

---

### **1. 核心组件架构图**   
<div class="mermaid">
flowchart LR
    A[知识库] --> B[检索器]
    C[用户查询] --> B
    B --> D[生成器]
    D --> E[答案]
</div>

---

### **2. 核心组件详解**
#### **（1）知识库（Knowledge Base）**
- **作用**：存储外部知识，供检索器查询。
- **关键技术**：
  - **文档预处理**：文本清洗、分块（chunking）、元数据标注（如来源、更新时间）。
  - **向量化**：使用嵌入模型（如 `text-embedding-ada-002`、`BGE`）将文本转换为向量。
  - **存储引擎**：
    - **向量数据库**：FAISS、Pinecone、Milvus（支持高效相似度搜索）。
    - **混合存储**：结合传统数据库（如Elasticsearch）处理结构化元数据。

#### **（2）检索器（Retriever）**
- **作用**：从知识库中找出与用户查询相关的文档片段。
- **关键技术**：
  - **查询向量化**：使用与知识库相同的嵌入模型处理用户输入。
  - **相似度算法**：余弦相似度、点积、欧氏距离。
  - **检索策略**：
    - **稠密检索**（Dense Retrieval）：基于向量相似度（主流方案）。
    - **稀疏检索**（如BM25）：适合关键词匹配场景。
    - **混合检索**：结合两者优势（如ColBERT）。
  - **优化技术**：
    - **重排序（Rerank）**：用小模型（如Cohere Rerank）对初步结果精排。
    - **查询扩展**：通过LLM改写查询提升召回率。

#### **（3）生成器（Generator）**
- **作用**：基于检索结果和用户查询生成最终答案。
- **关键技术**：
  - **Prompt工程**：
    ```python
    prompt = f"""
    基于以下信息回答问题：
    {context_1}
    {context_2}
    问题：{query}
    """
    ```
  - **模型选择**：
    - 通用LLM：GPT-4、Claude、Llama 2。
    - 领域微调模型：如医疗领域的BioGPT。
  - **生成控制**：
    - **引用机制**：要求模型标注答案来源（如“根据文档A所述…”）。
    - **幻觉抑制**：通过提示词约束（如“仅基于给定信息回答”）。

#### **（4）增强组件（可选但关键）**
- **查询理解模块**：
  - 意图识别：分类用户问题类型（如事实型/观点型）。
  - 实体链接：识别查询中的关键实体（如人名、公司名）。
- **后处理模块**：
  - 答案校验：检查生成内容与检索结果的一致性。
  - 格式化输出：提取结构化数据（如表格、列表）。

---

### **3. 组件交互流程**
<div class="mermaid">
sequenceDiagram
    participant User
    participant Retriever
    participant KnowledgeBase
    participant Generator
    User->>Retriever: 发送查询(query)
    Retriever->>KnowledgeBase: 向量化查询并检索
    KnowledgeBase-->>Retriever: 返回Top-K文档
    Retriever->>Generator: 拼接Prompt（查询+上下文）
    Generator->>Generator: LLM生成答案
    Generator-->>User: 返回最终答案
</div>

---

### **4. 开源工具链示例**

| 组件        | 常用工具/框架                              |
|-------------|------------------------------------------|
| **知识库**  | LangChain Document Loaders, LlamaIndex   |
| **向量库**  | FAISS, Milvus, Weaviate                  |
| **检索器**  | Sentence-Transformers, DPR, BM25         |
| **生成器**  | HuggingFace Transformers, OpenAI API     |
| **全栈**    | LangChain, Haystack, DSPy                |

---

### **5. 关键设计考量**
1. **分块策略**：
   - 小块（128-256 tokens）：适合精确问答。
   - 大块（512+ tokens）：适合需要上下文的理解任务。
2. **检索-生成平衡**：
   - 若检索结果差，限制LLM回答“未找到相关信息”。
3. **冷启动问题**：
   - 用小规模种子数据（如FAQ）初始化检索器。

---

### **6. 典型案例**
- **客服系统**：
  - 知识库：产品手册+工单历史。
  - 检索器：混合检索（BM25+向量）。
  - 生成器：GPT-4 + 引用格式约束。
- **学术助手**：
  - 知识库：ArXiv论文库（按学科分块）。
  - 检索器：基于SPECTER嵌入的语义搜索。
  - 生成器：Llama 2 + 自动参考文献生成。

---

### **总结**
RAG的四大核心组件（**知识库**、**检索器**、**生成器**、**增强模块**）共同实现：
**动态知识注入** + **可控生成**。设计时需权衡：
- 检索效率（速度 vs 召回率）
- 生成质量（事实性 vs 流畅性）
- 系统复杂度（是否需要实时更新）。